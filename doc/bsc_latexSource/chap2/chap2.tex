\XeTeXinputencoding cp1250

% ********** Chapter 2 **********
\chapter{Noþiuni teoretice}
\label{sec:chapter2}

\section{Abordãri ale temei în literatura de specialitate}

În funcþie de restricþiile aplicaþiei practice în care este utilizatã, recunoaºterea obiectelor poate lua mai multe forme, de la simpla împãrþire a imaginii în zone ce pot reprezenta obiecte (segmentare pe bazã de culoare), la o recunoaºtere completã, ce implicã determinarea locaþiei $(x,y)$ a unui obiect, reconstituirea poziþionãrii sale în spaþiu (sau 2D în planul imaginii) ºi recunoaºterea denumirii obiectului respectiv pe baza unor cunoºtiinþe anterioare ale sistemului.

Oricare ar fi gradul de complexitate, la modul general se pune problema ca pornind de la o matrice de pixeli (imaginea), sã fie determinatã o submulþime a acestora care reprezintã un obiect. Fãrã a scãdea din generalitate, considerãm cã obiectul este dat de o regiune contiguã de pixeli din imaginea originalã. 

O abordare directã a problemei, presupunând cã deþinem o imagine a obiectului, ar fi cãutarea tuturor pixelilor sãi într-o altã imagine datã. Îmbunãtãþiri ale acestei metode, caracterizatã de potrivirea unor "tipare" reprezentând obiectul în scene care îl conþin, au reprezentat începutul cercetãrii în domeniu (Figura \ref{fig:chap2:templatematching}). Soluþia (\textbf{template matching}\index{template matching}), în forma ei iniþialã, este ineficientã computaþional ºi sensibilã atât la modificãri ale mediului în care dorim sã realizãm recunoaºterea (luminozitate, reflexii) cât ºi la ocluzionãri parþiale ale obiectelor. Pentru obþinerea unei oarecare invarianþe, a fost propusã corelarea nivelurilor de gri din diverse zone ale imaginii reprezentând obiectul, cu zone din imagini care se presupune cã îl conþin.~\cite{Ballard82, Goshtasby84} Aceste studii sunt fãcute în contextul sistemelor de stereo-vizualizare, unde scena este fotografiatã simultan din perspective diferite ºi se doreºte determinarea unor corespondenþe între imagini, evitând o calibrare anterioarã sau cunoaºterea geometriei epipolare a sistemului. Mai recent, existã variante care propun modificãri ale metodei pentru a o putea rula în timp real~\cite{Cole04visualobject}.

Pentru a depãºi o parte din problemele metodei anterioare, se pleacã de la observaþia cã pentru recunoaºterea unui obiect nu este nevoie de toþi pixelii sãi, ci doar de o parte din aceºtia, ce definesc forma specificã a obiectului sau caracteristici importante ale acestuia. Se realizeazã o sintetizare a informaþiei din imaginea originalã, fãcându-se primul pas înspre reprezentarea respectivului obiect într-un mod abstract. Abordarea recunoaºterii obiectelor prin potrivirea unor astfel de trãsãturi abstracte (\textbf{feature matching}\index{feature matching}) este cea de-a doua direcþie de cercetare în domeniu. (Figura \ref{fig:chap2:featurematching})

Aplicarea algoritmilor de acest tip presupune marcarea trãsãturilor din imagine ca puncte de interes, având ca informaþie minimalã locaþia, $(x_t,y_t)$. Existã desigur ºi posibilitatea stocãrii unor date suplimentare precum orientarea sau scala caracteristicii determinate. 

În mod tradiþional, trãsãturile alese pentru identificare ºi potrivire sunt muchii, colþuri sau contururi~\cite{Cheng84, Ullman79}. În momentul de faþã, sunt propuºi algoritmi care realizeazã ºi identificarea unor alte structuri, precum petele luminoase sau întunecate (eng. blob)~\cite{Lowe03distinctiveimage,Bay06surf:speeded}\index{blob}.

\begin{figure}[htbp]
\numberwithin{figure}{chapter}
\centering
\subfloat[][]{
\includegraphics[scale=0.5]{chap2/template_matching.png}
\label{fig:chap2:templatematching}
}
\subfloat[][]{
\includegraphics[scale=0.5]{chap2/feature_matching.png}
\label{fig:chap2:featurematching}
}
\label{fig:chap2:matching}
\caption[Potrivire bazatã pe tipare / Potrivire bazatã pe trãsãturi]{\subref{fig:chap2:templatematching}: Potrivire bazatã pe tipare (template matching),~\subref{fig:chap2:featurematching}: Potrivire bazatã pe trãsãturi (feature matching)}
\end{figure}

Avantajul acestei metode este cã necesitã mai puþinã putere de calcul (operând asupra unui numãr relativ restrâns de pixeli) ºi poate fi, prin urmare, aplicatã cu uºurinþã în timp real. În plus, datoritã faptului cã se lucreazã cu o reprezentare intermediarã a obiectului (trãsãturi), metodele pot fi proiectate pentru a obþine un grad ridicat de invarianþã la anumiþi parametrii de mediu sau la transformãri afine aplicate obiectului. Abordarea eºueazã dacã nu se reuºeºte o determinare repetabilã ºi consistentã a trãsãturilor unui obiect în imagini diferite. În acest caz, potrivirea nu are loc ºi obiectul nu este detectat.

Datoritã flexibilitãþii crescute ºi a rezultatelor foarte bune obþinute în practicã de cãtre abordarea potrivirii bazate pe trãsãturi, lucrarea de faþã utilizeazã aceastã metodã pentru recunoaºterea obiectelor.

\section{Identificarea trãsãturilor}

În identificarea trãsãturilor, se disting 2 metode, utilizate, cu unele adaptãri, în cele mai multe dintre aplicaþiile practice curente: Detectorul Harris, ºi SIFT (Scale Invariant Feature Transform). Aplicaþia propusã în lucrare utilizeazã o variantã îmbunãtãþitã a algoritmului SIFT, adaptatã pentru procesarea fluxurilor de imagini, în timp real. O parte a ideilor propuse iniþial de Harris si Stephens pentru detectorul Harris sunt reluate în algoritmul SIFT, prin urmare considerãm utilã prezentarea ambelor metode.

\subsection{Detectorul Harris}
Prima abordare, propusã de Harris ºi Stephens\index{detector Harris}, identificã în imagine colþurile ºi muchiile~\cite{Harris88acombined}. Cei doi pornesc de la o observaþie anterioarã a lui Moravec, care defineºte un colþ ca fiind un pixel care nu se aseamãnã cu pixelii din vecinãtatea sa. Astfel, pe o suprafaþã uniformã, un pixel va avea valori apropiate de cele ale vecinilor sãi; pe o muchie, în vecinãtatea pixelului se vor identifica modificãri mari relativ la valorile vecinilor perpendiculari pe direcþia muchiei, dar modificãri mici în direcþia muchiei. Însã dacã pixelul aparþine unei trãsãturi cu variaþii în toate direcþiile (un colþ), atunci nici una dintre vecinãtãþi nu va fi similarã pixelului. În~\cite{Harris88acombined}, formalizând matematic aceste observaþii, se defineºte noþiunea de autocorelaþie. Funcþia de autocorelaþie mãsoarã modificãrile locale ale semnalului 2D (imaginea), folosind ferestre deplasate pe distanþe mici în vecinãtatea punctului considerat. Fiind datã o deplasare $(\Delta{}x, \Delta{}y)$ ºi un punct $(x,y)$, funcþia de autocorelaþie este 
\begin{equation}
E(\Delta{}x, \Delta{}y)=\sum_{x,y}w(x,y)[I(x+\Delta{}x,y+\Delta{}y)-I(x,y)]^2
\label{eq:chap2:autocorelatie}
\end{equation} 
unde $w(x,y)$ reprezintã funcþia fereastrã (ºi poate fi aleasã ca fiind o funcþie nucelu rectangularã sau, pentru a reduce influenþa zgomotului, un nucleu Gaussian) iar $I(\cdot{},\cdot)$ este funcþia imagine.

Imaginea din fereastra deplasatã este aproximatã prin dezvoltarea în serie Taylor, trunchiatã la primii termeni,
\begin{equation}
I(x+\Delta{}x,y+\Delta{}y)=I(x,y)+
\left[ \begin{array}{cc}
I_x & I_y \end{array}\right]
\left[\begin{array}{c}
\Delta{}x\\
\Delta{}y \end{array}\right]
\label{eq:chap2:taylorexp}
\end{equation}
$I_x$ ºi $I_y$ fiind derivatele parþiale pe direcþia x, respectiv y.

Înlocuind \ref{eq:chap2:taylorexp} în \ref{eq:chap2:autocorelatie} ºi considerând $\Delta{}x$ ºi $\Delta{}y$ suficient de mici, obþinem o ecuaþie de forma:

\begin{equation*}
E(\Delta{}x, \Delta{}y) \cong
\left[ \begin{array}{cc}
\Delta{}x & \Delta{}y \end{array}\right]
M
\left[\begin{array}{c}
\Delta{}x\\
\Delta{}y \end{array}\right]
\end{equation*}
M fiind o matrice $2\times{}2$ calculatã din derivatele locale parþiale ale imaginii,
\begin{equation*}
M=\sum_{x,y}w(x,y)
\left[ \begin{array}{cc}
I_x^2     & I_x{}I_y\\
 I_x{}I_y & I_y^2    \end{array}\right]
\end{equation*}

Matricea M descrie structura localã a imaginii în vecinãtatea pixelului considerat. 

Fie $\lambda_1, \lambda_2$ valorile proprii ale acestei matrici. Existã 3 cazuri care trebuie considerate:
\begin{enumerate}
\item Dacã atât $\lambda_1$ cât ºi $\lambda_2$ au valori mici, astfel încât funcþia de autocorelaþie este platã (schimbãri mici ale lui $E(\Delta{}x, \Delta{}y)$ în orice direcþie), zona din fereastra consideratã este aproximativ uniformã.
\item Dacã o valoare proprie este mare iar cealaltã este micã, astfel încât funcþia de autocorelaþie are forma unei trepte, atunci deplasãrile ferestrei într-o direcþie (de-a lungul treptei) produc modificãri mici ale lui E, iar deplasãrile pe o direcþie ortogonalã primeia produc modificãri mari. Acest lucru indicã o muchie.
\item Dacã valorile proprii sunt ambele mari, deplasãrile în orice direcþie vor produce modificãri mari ale lui E, indicând un colþ.

\end{enumerate}

\begin{figure}[htbp]
\numberwithin{figure}{chapter}
\centering
\includegraphics[scale=0.7]{chap2/harris_detector.png}
\caption{Detectorul Harris (muchii ºi colþuri)}
\label{fig:chap2:harrisdetector}
\end{figure}
Intuitiv, modul de operare al detectorului Harris este prezentat în Figura~\ref{fig:chap2:harrisdetector}. Performanþele sale au fost analizate în detaliu \cite{Schmid00}. Concluzia studiului este cã detectorul Harris este unul robust, putând fi aplicat cu succes inclusiv pe imagini afectate de zgomot ºi fiind invariant la rotaþii sau schimbãri ale luminozitãþii ambientale. Totuºi, repetabilitatea rezultatelor sale scade drastic la schimbãri ale perspectivei. O altã problemã a detectorului este cã nu este invariant la modificãrile de scalã ale obiectelor considerate. Acest lucru poate fi observat cu uºurinþã în Figura~\ref{fig:chap2:harrisscale}.
\begin{figure}[htbp]
\numberwithin{figure}{chapter}
\centering
\includegraphics[scale=0.7]{chap2/harris_scale.png}
\caption[Variaþia rezultatelor detectorului Harris la scalãri]{{\em Variaþia rezultatelor detectorului Harris la scalãri:} modificarea scalei imaginii poate duce la clasificãri diferite}
\label{fig:chap2:harrisscale}
\end{figure}

Au fost propuse ºi variante care sã fie invariante la scalãri (Harris-Laplacian), acestea fiind similare ca abordare cu cel de-al doilea detector important, SIFT.

\subsection{Detectorul SIFT}
SIFT (Scale Invariant Feature Transform)\label{sym:SIFT}\index{SIFT} este un algoritm propus de Lowe \cite{Lowe03distinctiveimage}, care include, ca pas intermediar, detecþia unor puncte de interes asimilate unor trãsãturi de tip "zonã luminoasã" sau "zonã întunecatã". Prin construcþia algoritmului, aceste zone sunt determinate pentru a fi invariante la scalãri, rotaþii ºi parþial invariante la modificãri ale luminozitãþii ºi la transformãri afine. Metoda aplicã o filtrare în cascadã, pentru a asigura calitatea punctelor de interes determinate, dar ºi pentru a aplica operaþiile intensive computaþional doar acelor zone care trec unele teste iniþiale. Pe lângã determinarea locaþiei punctelor de interes, algoritmul SIFT propune ºi metode de descriere a acestora în mod individual, astfel încât sã poatã fi identificate cu probabilitate mare în imagini noi. Practic, fiecãrui punct de interes îi este asociat un descriptor (vector caracteristic), calculat pe baza informaþiilor imaginii în vecinãtatea punctului de interes. 

Aceste caracteristici recomandã SIFT ca fiind ideal pentru aplicarea în zona recunoaºterii obiectelor~\cite{Lowe99objectrecognition}. Pentru aceasta, mai intâi se extrag trãsãturile SIFT pentru un set de imagini de referinþã ce reprezintã obiectele, stocând descriptorii rezultaþi \mbox{într-o} bazã de date. Unei imagini noi, în care se doreºte identificarea unuia dintre obiectele existente în baza de date, i se aplicã acelaºi algoritm, iar descriptorii punctelor de interes rezultate sunt comparaþi individual cu descriptorii din baza de date. Potrivirile între descriptori se fac pe baza distanþei Euclidiene între vectori (nu se cautã doar potriviri exacte). Totuºi, într-o imagine aglomeratã, multe trãsãturi din fundal nu vor avea corespondenþi în baza de date, dând potriviri false, pe lângã cele corecte. Potrivirile corecte pot fi însã filtrate prin identificarea unor submulþimi de puncte de interes care sunt consistente cu aceeaºi localizare, scalã ºi orientare a obiectului în noua imagine. Determinarea acestor clustere poate fi realizatã eficient folosind transformata Hough~\cite{Brown02:invariantfeatures}.

\subsubsection{Localizarea punctelor de interes}
Primul pas în determinarea punctelor de interes SIFT îl reprezintã detectarea locaþiilor din imagine care sunt invariante la scalãri, prin cãutarea trãsãturilor stabile, folosind o funcþie de scalã cunoscutã sub denumirea de spaþiu al scalãrilor (eng. scale space\index{scale space}\index{spaþiul scalãrilor}). Pentru o imagine, spaþiul scalãrilor este definit de funcþia $L(x,y,\sigma)$, obþinutã prin convoluþia unui nucleu Gaussian $G(x,y,\sigma)$ cu imaginea, $I(x,y)$. Pentru a obþine scalãri diferite, se variazã $\sigma$:
\begin{equation*}
L(x,y,\sigma)=G(x,y,\sigma)*I(x,y),
\end{equation*} 
unde $*$ reprezintã operaþia de convoluþie, iar nucleul Gaussian G\index{nucleu gaussian} este dat de formula:
\begin{equation*}
G(x,y,\sigma)=\frac{1}{2\pi\sigma^2}e^{-\frac{x^2+y^2}{2\sigma^2}}
\end{equation*} 

Pentru a detecta punctele de interes stabile în spaþiul scalãrilor, Lowe propune determinarea extremelor locale ale funcþiei "diferenþã de nuclee Gauss cu scalãri diferite", în convoluþie cu imaginea, $D(x,y,\sigma)$. Aceasta poate fi calculatã din diferenþa a douã scalãri separate de un factor $k$:
\begin{eqnarray}
D(x,y,\sigma)&=&(G(x,y,k\sigma)-G(x,y,\sigma))*I(x,y)\\
             &=&L(x,y,k\sigma)-L(x,y,\sigma)
\label{eq:chap2:diffGauss}
\end{eqnarray}

Existã mai multe motive pentru care a fost aleasã aceastã funcþie în mod particular. În primul rând, imaginile pentru care se aplicã filtrul Gaussian (convoluþie), trebuie oricum calculate în procesul de creare al spaþiului scalãrilor, D calculându-se în mod eficient prin scãderea imaginilor din douã scale adiacente. În al doilea rând, diferenþa nucleelor Gauss (Difference of Gaussian, DOG\label{sym:DOG}\index{DOG}) aproximeazã foarte bine Laplacianul Gaussian-ului, $\sigma^2\nabla^2G$. S-a demonstrat cã extremele aceastei funcþii reprezintã trãsãturi foarte stabile ale imaginii, în comparaþie cu trãsãturile determinate cu alte funcþii precum gradientul, Hessian-ul sau detectorul Harris\index{detector Harris}.

Pentru a detecta extremele locale ale funcþiei D, se realizeazã o eºantionare a funcþiei atât spaþial $(x,y)$, cât ºi pentru parametrul de scalã $(\sigma)$. Frecvanþa aleasã pentru eºantionare reprezintã un compromis între precizia localizãrii extremelor ºi puterea de calcul necesarã pentru determinarea lor. Astfel, o eºantionare cu frecvenþã mare duce la costuri mari din punct de vedere computaþional, iar o frecvenþã micã duce la o precizie scãzutã a algoritmului.

Fiecare punct eºantionat este comparat cu cei 8 vecini ai sãi din imaginea curentã, ºi cei 9 vecini din scalãrile adiacente celei curente (Figura~\ref{fig:chap2:siftscale}). Punctul este selectat doar dacã este mai mare sau mai mic comparativ cu toþi vecinii sãi. Aceastã abordare se dovedeºte eficientã pentru cã majoritatea punctelor sunt eliminate dupã doar câteva comparaþii.
\begin{figure}[htbp]
\numberwithin{figure}{chapter}
\centering
\includegraphics[scale=0.7]{chap2/sift_scale.png}
\caption[SIFT: Detectarea minimelor ºi maximelor locale]{{\em SIFT: Detectarea minimelor ºi maximelor locale;} punctul central este comparat cu toþi vecinii marcaþi (\cite{Lowe03distinctiveimage})}
\label{fig:chap2:siftscale}
\end{figure}

O precizie crescutã a localizãrii punctelor de interes se poate obþine folosind o metodã de aproximare a poziþionãrii maximului, prin interpolare. Astfel, se încearcã aproximarea punctelor eºantionate cu o funcþie cuadricã, 3D. Practic, se realizeazã o dezvoltare în serie Taylor pânã la termenii de grad 2, a funcþiei $D(x,y,\sigma)$, translatã astfel încât punctul eºantionat sã fie în origine:
\begin{equation}
D({\mathbf x})=D+\frac{\partial D}{\partial{\mathbf x}}^T{\mathbf x}+
\frac{1}{2}{\mathbf x^T}\frac{\partial^2 D}{\partial{\mathbf x^2}}{\mathbf x}
\label{eq:chap2:sifttaylor}
\end{equation}
unde D ºi derivatele sale sunt evaluate în punctul de eºantionare iar ${\mathbf x}=(x,y,\sigma)^T$ este deplasarea faþã de acest punct. Localizarea precisã a extremului, $\hat{\mathbf x}$ este determinatã prin derivarea ecuaþiei \ref{eq:chap2:sifttaylor} în raport cu ${\mathbf x}$ ºi egalarea cu zero, rezultând
\begin{equation}
\hat{\mathbf x}=-\frac{\partial^2 D}{\partial{\mathbf x^2}}^{-1}
\frac{\partial D}{\partial{\mathbf x}}
\label{eq:chap2:siftinterpolatedextr}
\end{equation}
Pentru a elimina punctele care sunt maxime locale dar se aflã într-o regiune cu un contrast slab (fiind prin urmare instabile), se vor reþine doar acelea pentru care $D(\hat{\mathbf x})$ este mai mare decât o valoare prag (Lowe alege valoarea de prag 0.03 pentru experimentele sale).

Totuºi, pentru o stabilitate crescutã, nu e suficientã îndepãrtarea trãsãturilor cu un contrast slab. Funcþia "diferenþã de nuclee Gauss" va avea un rãspuns puternic de-a lungul muchiilor, chiar dacã locaþia respectivã este determinatã imprecis, sensibilã la zgomotele din imagine. Pentru eliminarea acestor rãspunsuri, se foloseºte o abordare bazatã pe o matrice Hessianã $2\times 2$, calculatã în poziþia ºi pentru scala punctului de interes:
\begin{equation}
{\mathbf H}=
\left[ \begin{array}{cc}
D_{xx} & D_{xy}\\
D_{xy} & D_{yy}\end{array}\right]
\label{eq:chap2:sifthessian}
\end{equation}

Derivatele se estimeazã prin diferenþele faþã de punctele eºantionate din vecinãtate. Pentru eliminarea rãspunsurilor de-a lungul muchiilor, se impune ca raportul valorilor proprii ale acestei matrici sã fie sub o valoare prag (Lowe alege valoarea 10). Pentru cã eliminarea se face în funcþie de raportul valorilor proprii, nu este necesarã calcularea individualã a acestora. În loc, se folosesc determinantul ºi urma matricii ${\mathbf H}$. Dacã notãm valorile proprii cu $\lambda_1$ ºi $\lambda_2$, atunci:
\begin{eqnarray*}
Tr({\mathbf H})  &=& D_{xx}+D_{yy} = \lambda_1+\lambda_2\\
Det({\mathbf H}) &=& D_{xx}D_{yy}-(D_{xy})^2 = \lambda_1 \lambda_2
\end{eqnarray*}
Considerãm arbitrar $\lambda_1>\lambda_2$ ºi notãm raportul valorilor proprii cu $r$, astfel încât $\lambda_1=r\lambda_2$. Atunci, avem:
\begin{equation}
\frac{Tr({\mathbf H})^2}{Det({\mathbf H})}=
\frac{(\lambda_1+\lambda_2)^2}{\lambda_1\lambda_2}=
\frac{(r\lambda_2+\lambda_2)^2}{r\lambda_2^2}=
\frac{(r+1)^2}{r}
\label{eq:chap2:eigraport}
\end{equation}
Prin urmare, pentru a impune r ca valoare prag, trebuie verificatã doar condiþia:
\begin{equation}
\frac{Tr({\mathbf H})^2}{Det({\mathbf H})}<
\frac{(r+1)^2}{r}
\label{eq:chap2:eigthreshold}
\end{equation}

\subsubsection{Descrierea punctelor de interes}
Dupã stabilirea precisã a locaþiei unei trãsãturi, se doreºte asocierea unui vector caracteristic (descriptor), astfel încât ea sã poatã fi identificatã ºi în alte imagini. 

Primul pas constã în atribuirea unei orientãri fiecãrui punct de interes, astfel încât descriptorul sã poatã fi reprezentat relativ la orientarea sa localã. Pentru operaþiile care urmeazã, se alege imaginea filtratã cu nucleu Gaussian având scala cât mai apropiatã de cea determinatã prin interpolare pentru punctul de interes. Folosind aceastã imagine, se calculeazã norma ºi orientarea gradientului într-un numãr de puncte din vecinãtatea punctului de interes. Valorile obþinute sunt organizate într-o histogramã a orientãrilor, cu 36 de intervale. Fiecare vector gradient este adãugat în intervalul corespunzãtor orientãrii sale ºi ponderat cu valoarea normei. Vârfurile din histogramã corespund orientãrilor dominante ale gradienþilor locali. Cel mai mare vârf este ales ca orientare a punctului de interes. Dacã cel de-al doilea vârf al histogramei este comparabil ca mãrime, atunci în aceeaºi poziþie din imagine se va crea un al doilea punct de interes, care sã aibã orientarea acestui al doilea vârf.

Parametrii de poziþie, scalã ºi orientare determinaþi pânã acum stabilesc un sistem de coordonate 2D, local punctului de interes, faþã de care se realizeazã descrierea acestuia.

În vecinãtatea determinatã de sistemul local de coordonate al punctului de interes se realizeazã o eºantionare, iar în punctele alese se calculeazã norma ºi orientarea gradientului, relativ la orientarea punctului de interes (Figura~\ref{fig:chap2:sifthistogram}). Normele sunt ponderate de o funcþie Gaussianã, (cercul din figurã) cu $\sigma$ de 1.5 ori mai mare decât dimensiunea vecinãtãþii considerate (în experimente $16\times 16$ pixeli). Vecinãtatea este împãrþitã apoi într-un numãr de subregiuni care nu se suprapun (16 regiuni de $4\times 4$ pixeli). Pentru fiecare subregiune, valorile gradienþilor sunt acumulate într-o histogramã, similarã celei folosite anterior. Dacã o histogramã discretizeazã unghiurile de orientare în 8 valori posibile, descriptorul punctului de interes va conþine $4\times 4\times 8=128$ elemente, obþinute prin concatenarea valorilor din toate histogramele. (Figura~\ref{fig:chap2:sifthistogram}).

\begin{figure}[htbp]
\numberwithin{figure}{chapter}
\centering
\includegraphics[scale=0.7]{chap2/sift_histo.png}
\caption[SIFT: Procesul de determinare al descriptorului]{{\em SIFT: Procesul de determinare al descriptorului;} pentru claritatea reprezentãrii, a fost aleasã o vecinãtate 8x8 a punctului de interes. Algoritmul foloseºte vecinãtãþi 16x16.}
\label{fig:chap2:sifthistogram}
\end{figure}

\section{Identificarea trãsãturilor în timp real}
\label{sec:chapter2:identificare_trasaturi_realtime}

Dintre cele 2 metode prezentate, SIFT \index{SIFT} se remarcã datoritã invarianþei la un numãr mare de parametrii precum ºi datoritã stabilitãþii punctelor de interes determinate. Totuºi, este evident cã aplicarea algoritmului SIFT implicã un numãr mult mai mare de operaþii în comparaþie cu alþi detectori (Harris). Deoarece majoritatea aplicaþiilor îl vor utiliza doar ca pas intermediar, se pune problema unei post-procesãri a punctelor de interes (de exemplu, pentru a identifica obiecte) ºi se doreºte ca ansamblul algoritmilor de procesare sã ruleze în timp real. În forma prezentatã, SIFT poate prelucra aproximativ 5 cadre (de dimensiune $650\times 315$) pe secundã. Prin urmare, se justificã o cãutare a unor îmbunãtãþiri care sã determine o scãdere a timpului de prelucrare, fãrã a afecta calitatea rezultatelor finale. 

\subsection{Detectorul SURF}
SURF (Speeded-Up Robust Features)\index{SURF}\label{sym:SURF} este una dintre soluþiile propuse în acest sens, fiind ºi metoda utilizatã de aplicaþia descrisã în aceastã lucrare. Deoarece majoritatea paºilor urmaþi sunt identici cu cei ai algoritmului SIFT, vom prezenta în continuare doar elementele noi pe care le aduce în comparaþie cu acesta.

Principalul pas de procesare al algoritmului SIFT în determinarea punctelor de interes îl reprezintã crearea spaþiului scalãrilor ºi convoluþia imaginilor cu nuclee Gauss. Filtrarea ulterioarã a extremelor se bazeazã pe matricea Hessianã ºi pe impunerea unor condiþii asupra valorilor proprii ale acesteia (\ref{eq:chap2:sifthessian}, \ref{eq:chap2:eigthreshold}). Reamintim cã pentru construcþia matricii hessiene, Lowe \cite{Lowe03distinctiveimage} propune folosirea diferenþei de nuclee Gauss pentru a aproxima Laplacianul Gaussian-ului. 

\begin{figure}[htbp]
\numberwithin{figure}{chapter}
\centering
\includegraphics[scale=0.4]{chap2/surfBoxFilters.png}
\caption[SURF: filtre de mediere în comparaþie cu filtrele obþinute prin derivarea de ordin 2 a nucleelor Gauss]{SURF: filtre de mediere în comparaþie cu filtrele obþinute prin derivarea de ordin 2 a nucleelor Gauss. Bay noteazã cu $D_{xx}$, $D_{yy}$ ºi $D_{xy}$ aproximãrile cu filtre de mediere.~\cite{CEvans09}}
\label{fig:chap2:surfBoxFilters}
\end{figure}
Pentru a îmbunãtãþi performanþele acestor etape ale algoritmului, Bay propune \cite{Bay06surf:speeded} utilizarea unor filtre compuse din filtre de mediere (eng. box filter) care sã aproximeze tot Laplacianul Gaussian-ului, dar care sã poatã fi calculate mai eficient. O comparaþie între aceste filtre ºi cele originale propuse de Lowe poate fi observatã în Figura~\ref{fig:chap2:surfBoxFilters}. Calculul eficient al convoluþiei imaginii cu aceste filtre, este realizat prin folosirea imaginilor integrale.

\subsubsection{Imagini Integrale}
O imagine integralã reprezintã o prelucrare a unei imagini date ca intrare, pentru a permite calculul în timp constant al sumei pixelilor din orice regiune rectangularã. Fiind datã o imagine de intrare I ºi un punct $(x,y)$, imaginea integralã este calculatã cu formula:
\begin{equation}
I_\Sigma(x,y)=\sum_{i=0}^{i\leq x}\sum_{j=0}^{j\leq y}I(x,y)
\label{eq:chap2:integralimg}
\end{equation}
Având la dispoziþie imaginea integralã, calculul sumei pixelilor dintr-o regiune oarecare se poate realiza prin doar 4 operaþii matematice. Dacã vom considera regiunea pentru care dorim sã calculãm suma ca fiind limitatã de colþurile A,B,C ºi D (precum în Figura~\ref{fig:chap2:squarearea}):
\begin{equation}
\sum=A+C-(B+D)
\label{eq:chap2:sumintegral}
\end{equation}
unde am considerat prin abuz de notaþie A,B,C ºi D ca reprezentând intensitãþile pixelilor din imaginea integralã în punctul respectiv.
\begin{figure}[htbp]
\numberwithin{figure}{chapter}
\centering
\includegraphics[scale=0.5]{chap2/squareArea.png}
\caption{Calculul sumei intensitãþii pixelilor folosind imagini integrale.}
\label{fig:chap2:squarearea}
\end{figure}
\subsubsection{Construirea spaþiului scalãrilor}
În cadrul algoritmului SIFT, imaginea era în mod repetat micºoratã, fiind în acelaºi timp implicatã în operaþii repetitive de convoluþie cu nuclee Gauss având scalãri diferite. Ineficienþa calculelor realizate astfel provine din necesitatea de a redimensiona imaginea, cât ºi datoritã faptului cã unele calcule nu pot fi realizate independent de calculele pentru nivelurile anterioare.

SURF, fiind avantajat de lucrul cu imagini integrale (ºi putând aplica filtrãrile asupra imaginii în timp constant indiferent de mãrimea filtrului), alege soluþia inversã: în locul micºorãrii imaginii, va fi realizatã o mãrire progresivã a dimensiunii filtrelor. Aceastã idee simplã dã ºi posibilitatea calculãrii mai multor niveluri din spaþiul scalãrilor în mod simultan (calculele nu mai depind de valori obþinute pe niveluri inferioare). O imagine sugestivã care prezintã comparaþia dintre cele douã metode poate fi observatã în Figura~\ref{fig:chap2:scalespacecomp}
\begin{figure}[htbp]
\numberwithin{figure}{chapter}
\centering
\includegraphics[scale=0.3]{chap2/scalespacecomp.png}
\caption{Construirea spaþiului scalãrilor, SURF/SIFT~\cite{CEvans09}}
\label{fig:chap2:scalespacecomp}
\end{figure}
Spaþiul scalãrilor este divizat într-un numãr de octave, unde printr-o octavã se întelege secvenþa de imagini obþinute prin convoluþia cu filtre de mediere care acoperã o dublare a scalei ($\sigma$). Dimensiunea primului filtru folosit este de $9\times 9$, iar acesta corespunde cu un filtru Gauss real cu $\sigma_b=1.2$~\cite{CEvans09}. Nivelurile succesive din spaþiul scalãrilor sunt obþinute prin redimensionarea filtrelor. Redimensionarea se face astfel încât filtrul sã-ºi pãstreze structura generalã, având un pixel central. Datoritã acestei redimensionãri proporþionale, se poate estima scala echivalentã a unui filtru Gaussian care ar produce acelaºi efect, folosind formula:
\begin{equation}
\sigma\approx\textrm{Dim. filtrului curent}\cdot\frac{\sigma_b}{\textrm{Dim. filtrului corespunzãtoare } \sigma_b}
\label{eq:chap2:sigmaapprox}
\end{equation}
iar dupã înlocuirea cu valori,
\begin{equation}
\sigma\approx\textrm{Dim. filtrului curent}\cdot\frac{1.2}{9}
\label{eq:chap2:sigmaapprox2}
\end{equation}
\subsubsection{Localizarea punctelor de interes}
Asemãnãtor ecuaþiilor \ref{eq:chap2:sifttaylor} ºi \ref{eq:chap2:siftinterpolatedextr}, algoritmul SURF realizeazã o interpolare pentru determinarea cu precizie de subpixel a locaþiei extremelor locale. Diferenþa constã în faptul cã aplicarea acestor ecuaþii se face asupra determinantului Hessian-ului, nu asupra diferenþei de nuclee Gauss în convoluþie cu imaginea:
\begin{equation}
H({\mathbf x})=H+\frac{\partial H}{\partial{\mathbf x}}^T{\mathbf x}+
\frac{1}{2}{\mathbf x^T}\frac{\partial^2 H}{\partial{\mathbf x^2}}{\mathbf x}
\label{eq:chap2:surftaylor}
\end{equation}
Este important de menþionat faptul cã, din analiza realizatã de \cite{Bay06surf:speeded}, aproximãrile fãcute în scopul de a reduce din calculul necesar pentru determinarea punctelor de interes nu influenþeazã în mod semnificativ rezultatele, acestea fiind comparabile cu cele ale algoritmului SIFT.
\subsubsection{Descrierea punctelor de interes}
\label{sec:chapter2:descrpctinteres}
Vectorul caracteristic determinat de SURF pentru fiecare punct de interes mãsoarã modul în care este distribuitã intensitatea pixelilor într-o vecinãtate a punctului. Pentru determinarea gradienþilor locali în mod eficient, sunt folosite wavelet-uri Haar. Acestea sunt filtre extrem de simple, dupã cum se poate observa ºi în Figura \ref{fig:chap2:haarWavelets}
\begin{figure}[htbp]
\numberwithin{figure}{chapter}
\centering
\includegraphics[scale=0.5]{chap2/haarWavelets.png}
\caption[Wavelet-uri Haar]{Wavelet-uri Haar, dintre care prima este utilizatã pentru determinarea gradienþilor pe direcþia x iar a doua pentru cei de pe direcþia y}
\label{fig:chap2:haarWavelets}
\end{figure}

Desigur, descrierea punctului de interes se realizeazã tot în 2 etape (la fel ca în cazul algoritmului SIFT). Mai întâi, punctului de interes îi este atribuitã o orientare, bazatã pe orientarea dominantã a gradienþilor din vecinãtate, iar apoi, în funcþie de aceastã orientare se calculeazã un descriptor.

Atribuirea orientãrii se realizeazã practic prin calculul rãspunsurilor unor filtre Haar de dimensiune $4\sigma$, într-o vecinãtate a punctului de interes de dimensiune $6\sigma$. Desigur, $\sigma$ reprezintã aici scala la care a fost determinat punctul de interes. Rãspunsurile sunt calculate în interiorul vecinãtãþii, folosind o eºantionare cu pas $\sigma$. Pentru a da o mai mare importanþã direcþiilor gradienþilor din puncte mai apropiate de punctul de interes, rezultatul este ponderat de o funcþie Gauss centratã pe punctul de inters. Nucleul Gaussian folosit este ales cu deviaþia standard egalã cu $2.5\sigma$.

O datã ponderate, rãspunsurile în direcþia x ºi cele în direcþia y pentru fiecare locaþie eºantionatã sunt reprezentate ca puncte într-un spaþiu vectorial, cu x pe abscisã ºi y pe ordonatã. În acest spaþiu se realizeazã determinarea orientãrii dominante, prin rotirea unei ferestre ºi însumarea vectorilor din respectiva fereastrã, aºa cum este prezentat în Figura~\ref{fig:chap2:surfOrientation}.
\begin{figure}[htbp]
\numberwithin{figure}{chapter}
\centering
\includegraphics[scale=0.5]{chap2/surfOrientation.png}
\caption{SURF: Determinarea orientãrii pentru un punct de interes~\cite{CEvans09}}
\label{fig:chap2:surfOrientation}
\end{figure}
 
Pentru determinarea vectorului caracteristic, se alege o vecinãtate de dimensiune $20\sigma$ în jurul punctului de interes, orientatã conform orientãrii punctului. (Toate calculele sunt realizate relativ la aceastã direcþie, cu scopul de a obþine invarianþa la rotaþii). Spre deosebire de SIFT, în cazul SURF aceastã vecinãtate este împãrþitã în mai puþine subregiuni, formându-se o grilã de dimensiune $4\times 4$. În cadrul fiecãrei subregiuni, sunt alese 25 de puncte dispuse la rândul lor pe o grilã regulatã, iar în fiecare dintre aceste puncte sunt calculate rãspunsurile pe direcþiile x ºi y ale filtrelor Haar. Pentru fiecare subregiune din cele 16, însumând rezultatele obþinute în respectiva zonã, rezultã un vector descriptor de tipul:
\begin{equation}
v_{subregiune}=\left[\sum dx,\sum dy,\sum\lvert dx \rvert,\sum\lvert dy \rvert \right] 
\end{equation}
,unde în prima jumãtate se reþin informaþii referitoare la direcþia vectorilor, iar în a doua jumãtate informaþii legate de norma lor.
Pentru cã fiecare dintre cele 16 subregiuni este asociatã unui vector cu 4 componente, vectorul descriptor general va fi compus din $16\times 4=64$ componente.
\subsection{Alegerea parametrilor de rulare ai algoritmilor}
În general, algoritmii descriºi pânã acum folosesc o serie de parametrii care determinã în mod decisiv acurateþea rezultatelor ºi nivelul de acoperire al unui obiect dintr-o imagine cu puncte de interes. Trebuie realizat un compromis având în vedere dorinþa de a menþine durata rulãrii algoritmului în limite reduse (pentru prelucrarea în timp real). Astfel, parametrii de rulare de la care se pleacã în lucrarea de faþã sunt urmãtorii:
\\
\\
\begin{tabular}{l|l}
Numãr de octave calculate & 3\\
Intervale/octavã          & 4\\
Frecvenþã eºantionare pentru determinarea extremelor & variabilã \\
Prag stabilitate (cf. ecuaþiei ~\ref{eq:chap2:eigthreshold}) & 5-25
\end{tabular}

\section{Potrivirea trãsãturilor}
O datã ce a fost aleasã metoda folositã în determinarea punctelor de interes asociate unor trãsãturi din imagine, se pune în mod natural problema potrivirii acestor puncte între imagini distincte ale aceluiaºi obiect. Cu alte cuvinte, dorim sã aflãm dacã în imaginea sau cadrul (eng. frame) curent existã puncte de interes similare cu unele determinate anterior. Pe baza acestei potriviri, putem decide daca un obiect este prezent sau nu în noua imagine.

În mod tradiþional, potrivirea trãsãturilor este realizatã prin corelare, utilizând geometria epipolarã (geometria sistemului fizic determinat de axul optic al camerei/camerelor foto ºi obiectele din scena fotografiatã) drept constrângere pentru asigurarea consistenþei rezultatelor ~\cite{Zhang95:robustepipolar,Beardsley96:3dmodel}. 

Aceastã metodã funcþioneazã bine pentru modificãri mici ale poziþiei obiectelor în scenã, însã eºueazã în momentul în care diferenþele de scalã sau de perspectivã sunt mari. Faptul cã simpla corelare pe baza geometriei nu este suficientã justificã folosirea descriptorilor (vectorilor caracteristici) locali, pentru fiecare punct de interes. Atât timp cât aceºti descriptori sunt determinaþi cu invarianþe la parametrii de mediu ºi poziþionare a camerei (precum în cazul algoritmilor de tip SIFT), potrivirea se poate realiza pe baza lor.

Lucrarea de faþã utilizeazã o potrivire simplã, bazatã pe suma pãtratelor diferenþelor între 2 vectori caracteristici (SSD, eng. Sum of Squared Differences):
\begin{equation}
SSD=\sum_0^n(f_i-d_i)^2
\label{eq:chap2:ssd}
\end{equation}
, unde n este dimensiunea vectorilor caracteristici, f este vectorul determinat pentru primul punct de interes iar d este vectorul pentru cel de-al doilea punct. Dacã aceastã diferenþã este sub o valoare prag, atunci cele douã puncte de interes sunt considerate identice (reprezentând aceeaºi trãsãturã a obiectului).

În literatura de specialitate au fost propuse ºi modele mai complexe, avantajul acestora fiind o îmbunãtãþire considerabilã a preciziei. În schimb, aplicarea lor presupune cerinþe mai ridicate asupra resurselor de calcul. 

Metoda aplicatã în \cite{Brown02:invariantfeatures} spre exemplu, presupune stabilirea unor grupuri de puncte de interes ºi identificarea lor în alte imagini. Clusterizarea se realizeazã pe baza transformatei Hough, iar trãsãturile definite de clustere sunt eficient potrivite între imagini utilizând arbori k-d (eng. k-d trees).  Pentru îmbunãtãþirea preciziei, se aplicã algoritmul RANSAC (RANdom SAmple Consensus), care determinã o estimare a transformãrii 2D prin care un set de puncte de interes (pentru obiectele cunoscute) este transformat în alt set (acela al grupãrilor de puncte de interes din imaginea curentã).

%********** End of chapter **********
